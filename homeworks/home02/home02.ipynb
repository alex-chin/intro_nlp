{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Практическое задание №2 «Создание признакового пространства»\n",
    "Продолжим обработку данных с Твиттера."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import columns as columns\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    49159 non-null  int64  \n",
      " 1   label                 31962 non-null  float64\n",
      " 2   tweet                 49159 non-null  object \n",
      " 3   cor_tweet             49159 non-null  object \n",
      " 4   tweet_token           49159 non-null  object \n",
      " 5   tweet_token_filtered  49159 non-null  object \n",
      " 6   tweet_stemmed         49159 non-null  object \n",
      " 7   tweet_lemmatized      49159 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('tweet_correction.pkl')\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform().\n",
    "Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с\n",
    "помощью max_df.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью max_features=1000.\n",
    "- Исключим стоп-слова с помощью stop_words='english'.\n",
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с\n",
    "помощью CountVectorizer.get_feature_names()."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer(binary=False,\n",
    "                                   analyzer='word',\n",
    "                                   max_df=0.9,\n",
    "                                   max_features=1000,\n",
    "                                   stop_words='english',\n",
    "                                   tokenizer=dummy,\n",
    "                                   preprocessor=dummy,\n",
    "                                   token_pattern=None)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k142\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       abl  absolut  accept  account  act  action  actor  actual  ad  adapt  \\\n39270    0        0       0        0    0       0      0       0   0      0   \n41317    0        0       0        0    0       0      0       0   0      0   \n45818    0        0       0        0    0       0      0       0   0      0   \n11960    0        0       0        0    0       0      0       0   0      0   \n29607    0        0       0        0    0       0      0       0   0      0   \n\n       ...  yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n39270  ...     0     0          0   0     0     0      0       0   0      0  \n41317  ...     0     0          0   0     0     0      0       0   0      0  \n45818  ...     0     0          0   0     0     0      0       0   0      0  \n11960  ...     0     0          0   0     0     0      0       0   0      0  \n29607  ...     0     0          0   0     0     0      0       0   0      0  \n\n[5 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abl</th>\n      <th>absolut</th>\n      <th>accept</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actual</th>\n      <th>ad</th>\n      <th>adapt</th>\n      <th>...</th>\n      <th>yeah</th>\n      <th>year</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youtub</th>\n      <th>yr</th>\n      <th>yummi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39270</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41317</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45818</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11960</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29607</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_stemmed = count_vectorizer.fit_transform(df.tweet_stemmed)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_stemmed.toarray(), columns=feature_names).sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k142\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       able  absolutely  account  act  action  actor  actually  adapt  add  \\\n26031     0           0        0    0       0      0         0      0    0   \n20683     0           0        0    0       0      0         0      0    0   \n38632     0           0        0    0       0      0         0      0    0   \n19802     0           0        0    0       0      0         0      0    0   \n25407     0           0        0    0       0      0         0      0    0   \n\n       adventure  ...  year  yes  yesterday  yo  yoga  york  young  youtube  \\\n26031          0  ...     0    0          0   0     0     0      0        0   \n20683          0  ...     0    0          0   0     0     0      0        0   \n38632          0  ...     0    0          0   0     0     0      0        0   \n19802          0  ...     0    0          0   0     0     0      0        0   \n25407          0  ...     0    0          0   0     0     0      0        0   \n\n       yr  yummy  \n26031   0      0  \n20683   0      0  \n38632   0      0  \n19802   0      0  \n25407   0      0  \n\n[5 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>able</th>\n      <th>absolutely</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actually</th>\n      <th>adapt</th>\n      <th>add</th>\n      <th>adventure</th>\n      <th>...</th>\n      <th>year</th>\n      <th>yes</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youtube</th>\n      <th>yr</th>\n      <th>yummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26031</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20683</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38632</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19802</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25407</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_lemmatized = count_vectorizer.fit_transform(df.tweet_lemmatized)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words_lemmatized.toarray(), columns=feature_names).sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform().\n",
    "Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "- Игнорируем слова, частота которых в документе строго превышает порог 0.9 с\n",
    "помощью max_df.\n",
    "- Ограничим количество слов, попадающий в мешок, с помощью max_features=1000.\n",
    "- Исключим стоп-слова с помощью stop_words='english'.\n",
    "- Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с\n",
    "помощью TfidfVectorizer.get_feature_names()."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(binary=False,\n",
    "                                   analyzer='word',\n",
    "                                   max_df=0.9,\n",
    "                                   max_features=1000,\n",
    "                                   stop_words='english',\n",
    "                                   tokenizer=dummy,\n",
    "                                   preprocessor=dummy,\n",
    "                                   token_pattern=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "       abl  absolut  accept  account  act  action  actor  actual   ad  adapt  \\\n38176  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n45330  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n43582  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n38259  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n21345  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0   \n\n       ...  yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n38176  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n45330  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n43582  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n38259  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n21345  ...   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n\n[5 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>abl</th>\n      <th>absolut</th>\n      <th>accept</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actual</th>\n      <th>ad</th>\n      <th>adapt</th>\n      <th>...</th>\n      <th>yeah</th>\n      <th>year</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youtub</th>\n      <th>yr</th>\n      <th>yummi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38176</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>45330</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>43582</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>38259</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>21345</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_stemmed = tfidf_vectorizer.fit_transform(df.tweet_stemmed)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "pd.DataFrame(bag_of_words_stemmed.toarray(), columns=feature_names).sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       able  absolutely  account  act  action  actor  actually  adapt  add  \\\n7027    0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n28610   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n19770   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n16690   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n40302   0.0         0.0      0.0  0.0     0.0    0.0       0.0    0.0  0.0   \n\n       adventure  ...  year  yes  yesterday   yo  yoga  york  young  youtube  \\\n7027         0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0   \n28610        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0   \n19770        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0   \n16690        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0   \n40302        0.0  ...   0.0  0.0        0.0  0.0   0.0   0.0    0.0      0.0   \n\n        yr  yummy  \n7027   0.0    0.0  \n28610  0.0    0.0  \n19770  0.0    0.0  \n16690  0.0    0.0  \n40302  0.0    0.0  \n\n[5 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>able</th>\n      <th>absolutely</th>\n      <th>account</th>\n      <th>act</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actually</th>\n      <th>adapt</th>\n      <th>add</th>\n      <th>adventure</th>\n      <th>...</th>\n      <th>year</th>\n      <th>yes</th>\n      <th>yesterday</th>\n      <th>yo</th>\n      <th>yoga</th>\n      <th>york</th>\n      <th>young</th>\n      <th>youtube</th>\n      <th>yr</th>\n      <th>yummy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7027</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>28610</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>19770</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16690</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40302</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_lemmatized = tfidf_vectorizer.fit_transform(df.tweet_lemmatized)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "pd.DataFrame(bag_of_words_lemmatized.toarray(), columns=feature_names).sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре,\n",
    "\n",
    "составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по\n",
    "изменяйте параметры что бы добиться лучшего скора) обратите внимание как\n",
    "падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же\n",
    "попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на\n",
    "качество сделайте выводы"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text       label\n0  Stuning even for the non-gamer: This sound tra...  __label__2\n1  The best soundtrack ever to anything.: I'm rea...  __label__2\n2  Amazing!: This soundtrack is my favorite music...  __label__2\n3  Excellent Soundtrack: I truly like this soundt...  __label__2\n4  Remember, Pull Your Jaw Off The Floor After He...  __label__2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Stuning even for the non-gamer: This sound tra...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The best soundtrack ever to anything.: I'm rea...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Amazing!: This soundtrack is my favorite music...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Excellent Soundtrack: I truly like this soundt...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n      <td>__label__2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "data = open('corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаем df\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "trainDF.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "stat_test_vectorizes = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def test_vectorizes(vectorizer, classifier, corpus, train_x, valid_x, train_y, valid_y):\n",
    "    vectorizer.fit(corpus)\n",
    "    xtrain_count = vectorizer.transform(train_x)\n",
    "    xvalid_count = vectorizer.transform(valid_x)\n",
    "\n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "    print('размерность вектора', xtrain_count.shape)\n",
    "\n",
    "    return accuracy_score(valid_y, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Бейслан простой эмбеддинг на основе частотности"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размерность вектора (7500, 31681)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k142\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', binary=False)\n",
    "classifier = linear_model.LogisticRegression()\n",
    "score = test_vectorizes(count_vect, classifier, trainDF['text'], train_x, valid_x, train_y, valid_y)\n",
    "stat_test_vectorizes.append(['CountVectorizer', score])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размерность вектора (7500, 3000)\n"
     ]
    }
   ],
   "source": [
    "count_vect = HashingVectorizer(analyzer='word', token_pattern=r'\\w{1,}', n_features=3000)\n",
    "classifier = linear_model.LogisticRegression(max_iter=300)\n",
    "score = test_vectorizes(count_vect, classifier, trainDF['text'], train_x, valid_x, train_y, valid_y)\n",
    "stat_test_vectorizes.append(['HashingVectorizer3000', score])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размерность вектора (7500, 100)\n"
     ]
    }
   ],
   "source": [
    "count_vect = HashingVectorizer(analyzer='word', token_pattern=r'\\w{1,}', n_features=100)\n",
    "classifier = linear_model.LogisticRegression(max_iter=300)\n",
    "score = test_vectorizes(count_vect, classifier, trainDF['text'], train_x, valid_x, train_y, valid_y)\n",
    "stat_test_vectorizes.append(['HashingVectorizer1000', score])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размерность вектора (7500, 3000)\n"
     ]
    }
   ],
   "source": [
    "count_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=3000)\n",
    "classifier = linear_model.LogisticRegression(max_iter=300)\n",
    "score = test_vectorizes(count_vect, classifier, trainDF['text'], train_x, valid_x, train_y, valid_y)\n",
    "stat_test_vectorizes.append(['TfidfVectorizer3000', score])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размерность вектора (7500, 300)\n"
     ]
    }
   ],
   "source": [
    "count_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=300)\n",
    "classifier = linear_model.LogisticRegression(max_iter=300)\n",
    "score = test_vectorizes(count_vect, classifier, trainDF['text'], train_x, valid_x, train_y, valid_y)\n",
    "stat_test_vectorizes.append(['TfidfVectorizer300', score])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "             Векторайзер  Точность\n0        CountVectorizer    0.8568\n1  HashingVectorizer3000    0.8308\n2  HashingVectorizer1000    0.6716\n3    TfidfVectorizer3000    0.8700\n4     TfidfVectorizer300    0.8248",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Векторайзер</th>\n      <th>Точность</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CountVectorizer</td>\n      <td>0.8568</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HashingVectorizer3000</td>\n      <td>0.8308</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HashingVectorizer1000</td>\n      <td>0.6716</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TfidfVectorizer3000</td>\n      <td>0.8700</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TfidfVectorizer300</td>\n      <td>0.8248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stat_test_vectorizes, columns=['Векторайзер', 'Точность'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Вывод:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Корпус данных включает 7,5 тысячи документов и словарь в 35 тысяч токенов. Задача заключалась в построении вектора (простейшего эмбеддинга) который сможет уловить закономерности в документах. Проверка способности уловить закономерности проверялась на решении задачи классификации логистической регрессии. Простейший частотный словарь дал приличную оценку - 86%\n",
    "Лучший результат показал механизм TfIdf при этом словарь был снижен в 10 раз. И даже при снижении словаря на два порядка (в 100 раз) точность осталась на уровне 83%."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}